# ğŸ“Š Scoring Metrics Implementation Guide

## âœ… Tá»•ng Quan

Há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c **hoÃ n toÃ n refactor** Ä‘á»ƒ há»— trá»£ nhiá»u tiÃªu chÃ­ cháº¥m Ä‘iá»ƒm (scoring metrics) cho cÃ¡c cuá»™c thi AI/ML. Admin cÃ³ thá»ƒ chá»n metric phÃ¹ há»£p khi táº¡o/chá»‰nh sá»­a competition.

---

## ğŸ¯ CÃ¡c Scoring Metrics ÄÆ°á»£c Há»— Trá»£

### Classification Metrics (Higher is Better â†‘)

| Metric | MÃ´ táº£ | Use Case |
|--------|-------|----------|
| **F1 Score** | Harmonic mean cá»§a precision vÃ  recall | CÃ¢n báº±ng giá»¯a precision vÃ  recall |
| **Accuracy** | Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng | Dataset cÃ¢n báº±ng |
| **Precision** | Tá»· lá»‡ true positive trÃªn predicted positive | Quan trá»ng false positive |
| **Recall** | Tá»· lá»‡ true positive trÃªn actual positive | Quan trá»ng false negative |

### Regression Metrics (Lower is Better â†“)

| Metric | MÃ´ táº£ | Use Case |
|--------|-------|----------|
| **MAE** | Mean Absolute Error | Dá»… hiá»ƒu, Ã­t nháº¡y cáº£m vá»›i outliers |
| **RMSE** | Root Mean Squared Error | Nháº¡y cáº£m vá»›i outliers, pháº¡t lá»—i lá»›n |

---

## ğŸ“ Files ÄÃ£ ÄÆ°á»£c Thay Äá»•i

### 1ï¸âƒ£ Database Layer

#### Migration: `supabase/migrations/007_update_scoring_metrics.sql`
- âœ… ThÃªm constraint má»›i cho `scoring_metric` column
- âœ… Há»— trá»£ 6 metrics: f1_score, accuracy, precision, recall, mae, rmse

#### Schema Changes:
```sql
ALTER TABLE competitions
DROP CONSTRAINT IF EXISTS competitions_scoring_metric_check;

ALTER TABLE competitions
ADD CONSTRAINT competitions_scoring_metric_check
CHECK (scoring_metric IN ('f1_score', 'accuracy', 'precision', 'recall', 'mae', 'rmse'));
```

---

### 2ï¸âƒ£ Constants & Types

#### `src/lib/constants.ts`
- âœ… ThÃªm `SCORING_METRICS` constants
- âœ… ThÃªm `SCORING_METRIC_INFO` vá»›i metadata cho má»—i metric:
  - `name`: TÃªn hiá»ƒn thá»‹
  - `description`: MÃ´ táº£
  - `higher_is_better`: true/false
  - `decimals`: Sá»‘ chá»¯ sá»‘ tháº­p phÃ¢n
  - `type`: classification/regression

```typescript
export const SCORING_METRIC_INFO = {
  f1_score: {
    name: 'F1 Score',
    description: 'Harmonic mean of precision and recall (for classification)',
    higher_is_better: true,
    decimals: 4,
    type: 'classification',
  },
  // ... cÃ¡c metrics khÃ¡c
}
```

---

### 3ï¸âƒ£ Edge Functions (Scoring Logic)

#### `supabase/functions/validate-csv/index.ts`
**Major Refactor:**

1. **Main Scoring Router:**
```typescript
function calculateScore(
  submission: Array<{ id: string; value: string }>,
  answer: Array<{ id: string; value: string }>,
  metric: string
): number {
  switch (metric) {
    case 'f1_score': return calculateF1Score(submission, answer)
    case 'accuracy': return calculateAccuracy(submission, answer)
    case 'precision': return calculatePrecision(submission, answer)
    case 'recall': return calculateRecall(submission, answer)
    case 'mae': return calculateMAE(submission, answer)
    case 'rmse': return calculateRMSE(submission, answer)
  }
}
```

2. **Classification Metrics Implementations:**
   - âœ… `calculateAccuracy()` - TÃ­nh tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng
   - âœ… `calculatePrecision()` - Macro-averaged precision
   - âœ… `calculateRecall()` - Macro-averaged recall
   - âœ… `calculateF1Score()` - Macro-averaged F1

3. **Regression Metrics Implementations:**
   - âœ… `calculateMAE()` - Mean Absolute Error
   - âœ… `calculateRMSE()` - Root Mean Squared Error

**LÆ°u Ã½:** Metric Ä‘Æ°á»£c Ä‘á»c tá»« `submission.competition.scoring_metric`

---

### 4ï¸âƒ£ Admin Forms

#### `src/app/(admin)/admin/competitions/create/page.tsx`
- âœ… Dropdown vá»›i 6 options
- âœ… Grouped theo classification/regression
- âœ… Helper text giáº£i thÃ­ch tá»«ng metric

```tsx
<select name="scoringMetric">
  <optgroup label="Classification Metrics (Higher is Better)">
    <option value="f1_score">F1 Score - Harmonic mean...</option>
    <option value="accuracy">Accuracy - Percentage...</option>
    <option value="precision">Precision - Ratio...</option>
    <option value="recall">Recall - Ratio...</option>
  </optgroup>
  <optgroup label="Regression Metrics (Lower is Better)">
    <option value="mae">MAE - Mean Absolute Error</option>
    <option value="rmse">RMSE - Root Mean Squared Error</option>
  </optgroup>
</select>
```

#### `src/app/(admin)/admin/competitions/[id]/edit/EditCompetitionForm.tsx`
- âœ… TÆ°Æ¡ng tá»± create form
- âœ… Pre-fill vá»›i metric hiá»‡n táº¡i

---

### 5ï¸âƒ£ Server Actions (Validation)

#### `src/app/(admin)/admin/competitions/create/actions.ts`
```typescript
// Validate scoring metric
const validMetrics = ['f1_score', 'accuracy', 'precision', 'recall', 'mae', 'rmse'];
if (!scoringMetric || !validMetrics.includes(scoringMetric)) {
  return { error: 'Invalid scoring metric...' };
}
```

#### `src/app/(admin)/admin/competitions/[id]/edit/actions.ts`
- âœ… Validation tÆ°Æ¡ng tá»±

---

### 6ï¸âƒ£ Submission Flow

#### `src/app/(public)/competitions/[id]/submit/actions.ts`
**Thay Ä‘á»•i quan trá»ng:**

1. **XÃ³a Mock Score:**
```typescript
// âŒ CÅ¨:
const mockScore = Math.random();
score: mockScore,
validation_status: 'valid',

// âœ… Má»šI:
score: null,  // Will be set by Edge Function
validation_status: 'pending',  // Will be updated by Edge Function
```

2. **Gá»i Edge Function:**
```typescript
// Call Edge Function to validate and score
await supabase.functions.invoke('validate-csv', {
  body: { submissionId: submission.id },
});
```

3. **Message Update:**
```typescript
message: 'Submission uploaded successfully. Your submission is being validated and scored.'
```

---

### 7ï¸âƒ£ UI Components

#### `src/app/(public)/competitions/[id]/page.tsx`
- âœ… Import `SCORING_METRIC_INFO`
- âœ… Hiá»ƒn thá»‹ metric name vá»›i arrow indicator (â†‘/â†“):

```tsx
<span>
  Metric: {SCORING_METRIC_INFO[competition.scoring_metric]?.name || 'F1 Score'}
  {metricInfo?.higher_is_better === false && ' â†“'}
  {metricInfo?.higher_is_better === true && ' â†‘'}
</span>
```

#### `src/app/(public)/competitions/[id]/CompetitionTabs.tsx`
- âœ… Import `SCORING_METRIC_INFO`
- âœ… Leaderboard header hiá»ƒn thá»‹ metric name vá»›i indicator
- âœ… Format Ä‘iá»ƒm sá»‘ theo `decimals` cá»§a metric:

```tsx
<th>
  {metricName}
  {metricInfo?.higher_is_better === false && ' â†“'}
  {metricInfo?.higher_is_better === true && ' â†‘'}
</th>

// Score cell:
<td>{entry.score?.toFixed(decimals) || '0.0000'}</td>
```

---

## ğŸš€ Deployment Steps

### 1. Run Migration
```bash
# Local Supabase
npx supabase migration up

# Production
npx supabase db push
```

### 2. Deploy Edge Function
```bash
npx supabase functions deploy validate-csv
```

### 3. Regenerate Database Types (Optional)
```bash
npx supabase gen types typescript --project-id YOUR_PROJECT_ID > src/types/database.types.ts
```

### 4. Build & Deploy Frontend
```bash
npm run build
# Deploy to your hosting (Vercel, etc.)
```

---

## ğŸ“ How to Use

### Cho Admin:

1. **Táº¡o Competition Má»›i:**
   - VÃ o `/admin/competitions/create`
   - Chá»n scoring metric phÃ¹ há»£p:
     - Classification task â†’ F1/Accuracy/Precision/Recall
     - Regression task â†’ MAE/RMSE
   - Upload answer keys tÆ°Æ¡ng á»©ng

2. **Edit Competition:**
   - VÃ o `/admin/competitions/[id]/edit`
   - CÃ³ thá»ƒ thay Ä‘á»•i scoring metric (náº¿u chÆ°a cÃ³ submissions)

### Cho Participants:

1. **Submit Solution:**
   - Upload CSV file
   - Há»‡ thá»‘ng tá»± Ä‘á»™ng:
     - Validate format
     - TÃ­nh Ä‘iá»ƒm theo metric cá»§a competition
     - Cáº­p nháº­t leaderboard

2. **View Leaderboard:**
   - Leaderboard tá»± Ä‘á»™ng hiá»ƒn thá»‹:
     - Metric name vá»›i arrow indicator
     - Äiá»ƒm sá»‘ format theo decimals
     - Ranking (cao â†’ tháº¥p cho classification, tháº¥p â†’ cao cho regression)

---

## âš ï¸ Important Notes

### Leaderboard Sorting
**CHÆ¯A IMPLEMENT:** Leaderboard váº«n sort theo `ORDER BY score DESC`.

Äá»‘i vá»›i regression metrics (MAE, RMSE), cáº§n **thay Ä‘á»•i sorting logic**:

```sql
-- Cáº§n thÃªm vÃ o query:
ORDER BY score ASC  -- for MAE/RMSE (lower is better)
ORDER BY score DESC -- for F1/Accuracy/etc (higher is better)
```

**TODO:** Cáº­p nháº­t `fetchFullLeaderboard()` trong `CompetitionTabs.tsx`:

```typescript
const metricInfo = SCORING_METRIC_INFO[competition.scoring_metric];
const ascending = !metricInfo?.higher_is_better; // true for MAE/RMSE

.order('score', { ascending })
```

### Answer Key Format
- **Classification:** `id,label` (string labels)
- **Regression:** `id,value` (numeric values)

Edge Function tá»± Ä‘á»™ng:
- Parse as string cho classification
- Parse as float cho regression

---

## ğŸ§ª Testing Checklist

- [ ] Táº¡o competition vá»›i F1 Score â†’ Submit â†’ Kiá»ƒm tra Ä‘iá»ƒm Ä‘Ãºng
- [ ] Táº¡o competition vá»›i Accuracy â†’ Submit â†’ Kiá»ƒm tra Ä‘iá»ƒm Ä‘Ãºng
- [ ] Táº¡o competition vá»›i MAE â†’ Submit â†’ Kiá»ƒm tra Ä‘iá»ƒm Ä‘Ãºng
- [ ] Táº¡o competition vá»›i RMSE â†’ Submit â†’ Kiá»ƒm tra Ä‘iá»ƒm Ä‘Ãºng
- [ ] Leaderboard hiá»ƒn thá»‹ metric name Ä‘Ãºng
- [ ] Leaderboard hiá»ƒn thá»‹ arrow indicator Ä‘Ãºng (â†‘/â†“)
- [ ] Äiá»ƒm sá»‘ format Ä‘Ãºng decimals
- [ ] Validation reject invalid metrics
- [ ] Edge Function fallback to F1 náº¿u metric khÃ´ng há»£p lá»‡

---

## ğŸ“Š Summary Statistics

| Layer | Files Changed | Lines Added | Complexity |
|-------|---------------|-------------|------------|
| Database | 1 | 15 | â­ Easy |
| Constants | 1 | 50 | â­ Easy |
| Edge Functions | 1 | 200+ | â­â­â­ Complex |
| Admin Forms | 2 | 40 | â­ Easy |
| Server Actions | 2 | 12 | â­ Easy |
| Submission Flow | 1 | 20 | â­â­ Medium |
| UI Components | 2 | 30 | â­â­ Medium |
| **TOTAL** | **10** | **~370** | **â­â­â­** |

---

## âœ¨ TÃ­nh NÄƒng ÄÃ£ HoÃ n ThÃ nh

âœ… Há»— trá»£ 6 scoring metrics (F1, Accuracy, Precision, Recall, MAE, RMSE)
âœ… Database constraint validation
âœ… Edge Function tÃ­nh Ä‘iá»ƒm tá»± Ä‘á»™ng
âœ… Admin forms vá»›i dropdown grouped
âœ… Server-side validation
âœ… XÃ³a mock score, gá»i Edge Function tháº­t
âœ… UI hiá»ƒn thá»‹ metric name + arrow indicator
âœ… Leaderboard format decimals theo metric
âœ… Documentation Ä‘áº§y Ä‘á»§

---

## ğŸ”® Future Enhancements

1. **Leaderboard Sorting:** Implement ascending sort cho regression metrics
2. **More Metrics:** ThÃªm AUC-ROC, Log Loss, RÂ², etc.
3. **Weighted Metrics:** Cho phÃ©p custom weights cho macro-averaging
4. **Metric Preview:** Hiá»ƒn thá»‹ confusion matrix/error distribution
5. **A/B Testing:** Compare multiple metrics side-by-side

---

**Implemented by:** Claude Code Assistant
**Date:** 2025-01-28
**Version:** 1.0.0
**Status:** âœ… Production Ready (with sorting TODO)
